{
    "presets": {
        "CIFAR10": {
            "data_size": 32,
            "data_dim": 256,
            "num_input_channels": 3,
            "num_latents": 128,
            "latents_dim": 512,
            "label_dim": 10,
            "num_cond_tokens": 1,
            "num_processing_layers": 2,
            "num_blocks": 3,
            "path_size": 2,
            "read_write_heads": 8,
            "compute_heads": 16,
            "latent_mlp_multiplier": 4,
            "data_mlp_multiplier": 2,
            "use_cond_token": true,
            "concat_cond_token_to_latents": true,
            "use_cond_rin_block": false
        },
        "IN-64-ABLATION": {
            "data_size": 64,
            "data_dim": 512,
            "num_input_channels": 3,
            "num_latents": 128,
            "latents_dim": 768,
            "label_dim": 1000,
            "num_cond_tokens": 1,
            "num_processing_layers": 4,
            "num_blocks": 4,
            "path_size": 8,
            "read_write_heads": 16,
            "compute_heads": 16,
            "latent_mlp_multiplier": 4,
            "data_mlp_multiplier": 4,
            "use_cond_token": true,
            "concat_cond_token_to_latents": true,
            "use_cond_rin_block": false
        },
        "IN-64-UNIFIED": {
            "data_size": 64,
            "data_dim": 128,
            "num_input_channels": 3,
            "num_latents": 128,
            "latents_dim": 768,
            "label_dim": 1000,
            "num_cond_tokens": 1,
            "num_processing_layers": 4,
            "num_blocks": 4,
            "path_size": 1,
            "read_write_heads": 4,
            "compute_heads": 16,
            "latent_mlp_multiplier": 4,
            "data_mlp_multiplier": 4,
            "use_cond_token": true,
            "concat_cond_token_to_latents": true,
            "use_cond_rin_block": false
        },
        "IN-128-UNIFIED": {
            "data_size": 128,
            "data_dim": 64,
            "num_input_channels": 3,
            "num_latents": 128,
            "latents_dim": 768,
            "label_dim": 1000,
            "num_cond_tokens": 1,
            "num_processing_layers": 4,
            "num_blocks": 4,
            "path_size": 1,
            "read_write_heads": 4,
            "compute_heads": 16,
            "latent_mlp_multiplier": 4,
            "data_mlp_multiplier": 4,
            "use_cond_token": true,
            "concat_cond_token_to_latents": true,
            "use_cond_rin_block": false
        },
        "IN-256-UNIFIED": {
            "data_size": 256,
            "data_dim": 24,
            "num_input_channels": 3,
            "num_latents": 128,
            "latents_dim": 768,
            "label_dim": 1000,
            "num_cond_tokens": 1,
            "num_processing_layers": 4,
            "num_blocks": 4,
            "path_size": 1,
            "read_write_heads": 4,
            "compute_heads": 16,
            "latent_mlp_multiplier": 4,
            "data_mlp_multiplier": 4,
            "use_cond_token": true,
            "concat_cond_token_to_latents": true,
            "use_cond_rin_block": false
        },
        "IN-512-UNIFIED": {
            "data_size": 512,
            "data_dim": 8,
            "num_input_channels": 3,
            "num_latents": 128,
            "latents_dim": 768,
            "label_dim": 1000,
            "num_cond_tokens": 1,
            "num_processing_layers": 4,
            "num_blocks": 4,
            "path_size": 1,
            "read_write_heads": 4,
            "compute_heads": 16,
            "latent_mlp_multiplier": 4,
            "data_mlp_multiplier": 4,
            "use_cond_token": true,
            "concat_cond_token_to_latents": true,
            "use_cond_rin_block": false
        },
        "IN-1024-UNIFIED": {
            "data_size": 1024,
            "data_dim": 4,
            "num_input_channels": 3,
            "num_latents": 128,
            "latents_dim": 768,
            "label_dim": 1000,
            "num_cond_tokens": 1,
            "num_processing_layers": 4,
            "num_blocks": 4,
            "path_size": 1,
            "read_write_heads": 4,
            "compute_heads": 16,
            "latent_mlp_multiplier": 4,
            "data_mlp_multiplier": 4,
            "use_cond_token": true,
            "concat_cond_token_to_latents": true,
            "use_cond_rin_block": false
        },
        "IN-64": {
            "data_size": 64,
            "data_dim": 512,
            "num_input_channels": 3,
            "num_latents": 128,
            "latents_dim": 1024,
            "label_dim": 1000,
            "num_cond_tokens": 1,
            "num_processing_layers": 4,
            "num_blocks": 4,
            "path_size": 4,
            "read_write_heads": 16,
            "compute_heads": 16,
            "latent_mlp_multiplier": 4,
            "data_mlp_multiplier": 4,
            "use_cond_token": true,
            "concat_cond_token_to_latents": true,
            "use_cond_rin_block": false
        },
        "IN-128": {
            "data_size": 128,
            "data_dim": 256,
            "num_input_channels": 3,
            "num_latents": 128,
            "latents_dim": 1024,
            "label_dim": 1000,
            "num_cond_tokens": 1,
            "num_processing_layers": 4,
            "num_blocks": 6,
            "path_size": 4,
            "read_write_heads": 16,
            "compute_heads": 16,
            "latent_mlp_multiplier": 4,
            "data_mlp_multiplier": 4,
            "use_cond_token": true,
            "concat_cond_token_to_latents": true,
            "use_cond_rin_block": false
        },
        "IN-256": {
            "data_size": 256,
            "data_dim": 512,
            "num_input_channels": 3,
            "num_latents": 256,
            "latents_dim": 1024,
            "label_dim": 1000,
            "num_cond_tokens": 1,
            "num_processing_layers": 4,
            "num_blocks": 6,
            "path_size": 8,
            "read_write_heads": 16,
            "compute_heads": 16,
            "latent_mlp_multiplier": 4,
            "data_mlp_multiplier": 4,
            "use_cond_token": true,
            "concat_cond_token_to_latents": true,
            "use_cond_rin_block": false
        },
        "IN-512": {
            "data_size": 512,
            "data_dim": 512,
            "num_input_channels": 3,
            "num_latents": 256,
            "latents_dim": 768,
            "label_dim": 1000,
            "num_cond_tokens": 1,
            "num_processing_layers": 6,
            "num_blocks": 6,
            "path_size": 8,
            "read_write_heads": 16,
            "compute_heads": 16,
            "latent_mlp_multiplier": 4,
            "data_mlp_multiplier": 4,
            "use_cond_token": true,
            "concat_cond_token_to_latents": true,
            "use_cond_rin_block": false
        },
        "IN-1024": {
            "data_size": 1024,
            "data_dim": 512,
            "num_input_channels": 3,
            "num_latents": 256,
            "latents_dim": 768,
            "label_dim": 1000,
            "num_cond_tokens": 1,
            "num_processing_layers": 8,
            "num_blocks": 6,
            "path_size": 8,
            "read_write_heads": 16,
            "compute_heads": 16,
            "latent_mlp_multiplier": 4,
            "data_mlp_multiplier": 4,
            "use_cond_token": true,
            "concat_cond_token_to_latents": true,
            "use_cond_rin_block": false
        },
        "K-600": {
            "data_size": 64,
            "data_dim": 512,
            "num_input_channels": 3,
            "num_latents": 256,
            "latents_dim": 1024,
            "label_dim": 1000,
            "num_cond_tokens": 1,
            "num_processing_layers": 4,
            "num_blocks": 6,
            "path_size": 4,
            "read_write_heads": 16,
            "compute_heads": 16,
            "latent_mlp_multiplier": 4,
            "data_mlp_multiplier": 4,
            "use_cond_token": true,
            "concat_cond_token_to_latents": true,
            "use_cond_rin_block": true,
            "num_frames": 16,
            "temporal_patch_size": 2
        }
    }
}